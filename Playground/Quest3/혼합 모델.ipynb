{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "045d9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605819bc",
   "metadata": {},
   "source": [
    "### 서브클래싱한 모델을 포함하는 함수형 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fdc3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features) #output 서브클래싱\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b758d7d",
   "metadata": {},
   "source": [
    "### 함수형 모델을 포함하는 서브클래싱 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b736b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))#함수형\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs) #함수형\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs) \n",
    "\n",
    "class MyModel(keras.Model): #서브클래싱\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab9566",
   "metadata": {},
   "source": [
    "# 내장된 훈련 루프와 평가 루프 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd7268b",
   "metadata": {},
   "source": [
    "### 표준 워크플로: compile(), fit(), evaluate(), predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4507de33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2942 - accuracy: 0.9129 - val_loss: 0.1487 - val_accuracy: 0.9577\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1639 - accuracy: 0.9542 - val_loss: 0.1332 - val_accuracy: 0.9631\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1391 - accuracy: 0.9627 - val_loss: 0.1138 - val_accuracy: 0.9707\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1127 - accuracy: 0.9722\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77efdd84",
   "metadata": {},
   "source": [
    "# 사용자 정의 지표 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "620b74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")#샘플 수 저장\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1]) #실제 레이블 원핫 인코딩\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred)) #차이 제곱 mse \n",
    "        self.mse_sum.assign_add(mse) # MSE 값을 mse_sum에 누적\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        #전체 샘플에 대한 평균 제곱 오차(MSE)를 계산하고, 그 제곱근을 반환\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a98cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2989 - accuracy: 0.9124 - rmse: 7.1818 - val_loss: 0.1449 - val_accuracy: 0.9595 - val_rmse: 7.3624\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1661 - accuracy: 0.9520 - rmse: 7.3537 - val_loss: 0.1228 - val_accuracy: 0.9672 - val_rmse: 7.4004\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1367 - accuracy: 0.9635 - rmse: 7.3867 - val_loss: 0.1137 - val_accuracy: 0.9701 - val_rmse: 7.4224\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1032 - accuracy: 0.9731 - rmse: 7.4374\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d55ba2",
   "metadata": {},
   "source": [
    "# 콜백 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cac1ad",
   "metadata": {},
   "source": [
    "### EarlyStopping 콜백과 ModelCheckpoint 콜백"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4793ae3f",
   "metadata": {},
   "source": [
    "**fit() 메서드에서 callbacks 매개변수 사용하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50499344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2965 - accuracy: 0.9120 - val_loss: 0.1537 - val_accuracy: 0.9550\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1657 - accuracy: 0.9537 - val_loss: 0.1241 - val_accuracy: 0.9659\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1438 - accuracy: 0.9622 - val_loss: 0.1211 - val_accuracy: 0.9697\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1279 - accuracy: 0.9670 - val_loss: 0.1224 - val_accuracy: 0.9710\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1189 - accuracy: 0.9710 - val_loss: 0.1084 - val_accuracy: 0.9737\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1106 - accuracy: 0.9726 - val_loss: 0.1120 - val_accuracy: 0.9763\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1061 - accuracy: 0.9754 - val_loss: 0.1109 - val_accuracy: 0.9778\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1067 - accuracy: 0.9758 - val_loss: 0.1174 - val_accuracy: 0.9767\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0960 - accuracy: 0.9780 - val_loss: 0.1242 - val_accuracy: 0.9786\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0948 - accuracy: 0.9788 - val_loss: 0.1208 - val_accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7b8dbdcda8e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping( #성능향상이 멈추면 중지\n",
    "        monitor=\"val_accuracy\",#정확도 모니터링\n",
    "        patience=2,#2번 epoch기준\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(#epoch끝에서 현재 가중치 저장\n",
    "        filepath=\"checkpoint_path.h5\",#파일 저장경로\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,#모델 성능이 좋아지지 않으면 덮어쓰지 않음\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])#정확도 모델 지표\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6cf0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.h5\") #모델 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e630f97c",
   "metadata": {},
   "source": [
    "### 사용자 정의 콜백 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d014d7d4",
   "metadata": {},
   "source": [
    "**Callback 클래스를 상속하여 사용자 정의 콜백 만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ff1f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs): #훈련이 시작할때\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):#배치처리 끝\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):#에포크끝\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "053eea58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2942 - accuracy: 0.9131 - val_loss: 0.1482 - val_accuracy: 0.9584\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1646 - accuracy: 0.9529 - val_loss: 0.1224 - val_accuracy: 0.9663\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1383 - accuracy: 0.9620 - val_loss: 0.1181 - val_accuracy: 0.9709\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1251 - accuracy: 0.9666 - val_loss: 0.1081 - val_accuracy: 0.9734\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1192 - accuracy: 0.9704 - val_loss: 0.1032 - val_accuracy: 0.9760\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1076 - accuracy: 0.9736 - val_loss: 0.1046 - val_accuracy: 0.9776\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1034 - accuracy: 0.9747 - val_loss: 0.1153 - val_accuracy: 0.9781\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0996 - accuracy: 0.9762 - val_loss: 0.1211 - val_accuracy: 0.9775\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0989 - accuracy: 0.9772 - val_loss: 0.1177 - val_accuracy: 0.9759\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0919 - accuracy: 0.9785 - val_loss: 0.1175 - val_accuracy: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7b8dbe0c5a60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f4918",
   "metadata": {},
   "source": [
    "### 텐서보드를 사용한 모니터링과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df983201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2912 - accuracy: 0.9141 - val_loss: 0.1444 - val_accuracy: 0.9589\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1615 - accuracy: 0.9545 - val_loss: 0.1162 - val_accuracy: 0.9679\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1355 - accuracy: 0.9628 - val_loss: 0.1131 - val_accuracy: 0.9696\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1227 - accuracy: 0.9681 - val_loss: 0.1169 - val_accuracy: 0.9727\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1149 - accuracy: 0.9715 - val_loss: 0.1122 - val_accuracy: 0.9755\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1105 - accuracy: 0.9735 - val_loss: 0.1099 - val_accuracy: 0.9774\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1042 - accuracy: 0.9754 - val_loss: 0.1150 - val_accuracy: 0.9754\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0949 - accuracy: 0.9770 - val_loss: 0.1131 - val_accuracy: 0.9798\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0969 - accuracy: 0.9781 - val_loss: 0.1147 - val_accuracy: 0.9786\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0929 - accuracy: 0.9786 - val_loss: 0.1159 - val_accuracy: 0.9788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7b8dac0f5a60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"./tb_logs\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ffc72",
   "metadata": {},
   "source": [
    "# 사용자 정의 훈련, 평가 루프 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fea88b",
   "metadata": {},
   "source": [
    "### 측정 지표의 저수준 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "244db533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"결과: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d1d5e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 지표: 2.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"평균 지표: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d80bffa",
   "metadata": {},
   "source": [
    "### 완전한 훈련과 평가 루프"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63920e6",
   "metadata": {},
   "source": [
    "**단계별 훈련 루프 작성하기: 훈련 스텝 함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb06b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))  # 입력층: 28x28 픽셀 이미지를 784개의 숫자로 펼쳐서 받음\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)  # 은닉층: 512개의 뉴런, ReLU 활성화 함수 사용\n",
    "    features = layers.Dropout(0.5)(features)  # 드롭아웃: 훈련 중에 50% 뉴런을 랜덤하게 꺼서 과적합 방지\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)  # 출력층: 10개의 뉴런, 각 숫자 클래스에 대한 확률 출력\n",
    "    model = keras.Model(inputs, outputs)  # 입력층과 출력층을 연결하여 모델 생성\n",
    "    return model\n",
    "\n",
    "\n",
    "# 2. MNIST 데이터 준비\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()  # 데이터셋 불러오기\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255  # 이미지 형태 변환 및 정규화\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255  # 테스트 이미지도 동일하게 처리\n",
    "train_images, val_images = images[10000:], images[:10000]  # 훈련 데이터와 검증 데이터 분리\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]  # 레이블도 분리|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c371d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mnist_model() #모델 가져옴\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy() #손ㄴ실함수\n",
    "optimizer = keras.optimizers.RMSprop() #옵티마이저\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]#지표\n",
    "loss_tracking_metric = keras.metrics.Mean()#평균지표\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape: #모델 예측 과정을 기록\n",
    "        predictions = model(inputs, training=True) #모델에게 inputs을 넣고 예측을 얻음\n",
    "        loss = loss_fn(targets, predictions) #손실계산\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)#기울기계산\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))#가중치업데이트\n",
    "\n",
    "    logs = {} #평가결과 저장\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions) #평가지표 업데이트\n",
    "        logs[metric.name] = metric.result() #평가지표의이름과 결과를 딕셔러니레 저장\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)#손실값을 추적하는 지표\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()#현재까지 평균 손실값 저장\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02b7c6",
   "metadata": {},
   "source": [
    "**단계별 훈련 루프 작성하기: 지표 재설정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e1d9252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_metrics(): #평가지표 초기화\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()#\n",
    "    loss_tracking_metric.reset_state() #지표초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe64c1d",
   "metadata": {},
   "source": [
    "**단계별 훈련 루프 작성하기: 훈련 루프 자체**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67079e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9674\n",
      "...loss: 0.1238\n",
      "1번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9699\n",
      "...loss: 0.1192\n",
      "2번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9735\n",
      "...loss: 0.1113\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:#배치학습\n",
    "        logs = train_step(inputs_batch, targets_batch)#각 배치에 대해 평가\n",
    "    print(f\"{epoch}번째 에포크 결과\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1930bce",
   "metadata": {},
   "source": [
    "### tf.function로 성능 높이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cc648e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 결과:\n",
      "...val_sparse_categorical_accuracy: 0.9736\n",
      "...val_loss: 0.1209\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"평가 결과:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac7170",
   "metadata": {},
   "source": [
    "###   fit() 메서드를 사용자 정의 훈련 루프로 활용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba234d3",
   "metadata": {},
   "source": [
    "**fit()이 사용할 사용자 정의 훈련 스텝 구현하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7c1fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "789a79d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2936\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1652\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7b8dac0e6760>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53c66602",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8aab41f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2948 - sparse_categorical_accuracy: 0.9127\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1648 - sparse_categorical_accuracy: 0.9523\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1376 - sparse_categorical_accuracy: 0.9634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7b8dbdd5eb50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1685ec7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
